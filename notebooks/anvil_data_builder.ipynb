{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dengue-anvil_classifier\n",
    "This classifier uses data from JSON delivered on October 2019 (dengue_fixed.json). To speed up retrieval, we used a filtered database from a MongoDB collection (ufmg_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../inputs/'\n",
    "outputs = '../outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import dns\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.twitter\n",
    "collection_ufmg = db.ufmg_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve data from Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% done\n"
     ]
    }
   ],
   "source": [
    "file_len = 7503436\n",
    "objects = collection_ufmg.find({})\n",
    "tweets_list = []\n",
    "data = pd.DataFrame()\n",
    "count = 0\n",
    "for obj in objects:\n",
    "    date = obj['date']\n",
    "    if isinstance(date, int):\n",
    "        date = date/1000\n",
    "    else: date = time.mktime(time.strptime(date[:10], '%Y-%m-%d'))\n",
    "    if date >= 1451617260: # 1451617260 = 2016-01-01\n",
    "        obj['date'] = time.strftime('%Y-%m-%d', time.localtime(date))\n",
    "        obj['text'] = re.sub(r'\\\\', '', obj['text'])\n",
    "        if 'extended_tweet' in obj: \n",
    "            obj['extended_tweet'] = re.sub(r'\\\\', '', obj['extended_tweet']['full_text'])\n",
    "        tweets_list.append(obj)\n",
    "\n",
    "    count += 1\n",
    "    if count % (int(file_len/1000)) == 0:\n",
    "        \n",
    "        #here I reset the list to save memory usage\n",
    "        if tweets_list: data = data.append(tweets_list, ignore_index=True)\n",
    "        tweets_list = []\n",
    "        \n",
    "        clear_output()\n",
    "        \n",
    "        frac = count/file_len*100\n",
    "        print(\"%.1f\" % frac, \"% done\", sep=\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_bak = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter by date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://portalarquivos2.saude.gov.br/images/pdf/2018/agosto/21/Publicacao-BE-2018-SE-30.pdf\n",
    "\n",
    "* zika\n",
    "    * peak year = 2016 \n",
    "    * peak week = week 7 = 14-21/2/2016\n",
    "    * occurrence timeframe = 7-14 = 14/2 a 9/4\n",
    "* chikungunya\n",
    "    * peak year = 2017 \n",
    "    * peak week = week 17 = 23-30/4/2017\n",
    "    * occurrence timeframe = 10-17 = 5/3 a 29/4\n",
    "* dengue\n",
    "    * peak year = 2016, but e used 2018 to add variability from other years\n",
    "    * occurrence timeframe = 14-21 = 1/4 a 26/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing 2018 for now because I want to compare with older anvil_input.\n",
    "\n",
    "notice that on older input, I chose different dates:\n",
    "```python\n",
    "data = data.loc[(data['date'] >= '2018-04-04 00:00:01') & (data['date'] <= '2018-05-27 23:59:59')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['date'] >= '2016-02-14 00:00:01') & (data['date'] <= '2016-05-28 23:59:59') \\\n",
    "                 | (data['date'] >= '2017-01-01 00:00:01') & (data['date'] <= '2017-08-20 23:59:59') \\\n",
    "                 | (data['date'] >= '2018-04-01 00:00:01') & (data['date'] <= '2018-05-27 23:59:59') \\\n",
    "    ]\n",
    "data = data[data['lang'] == 'pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>class_campanha</th>\n",
       "      <th>class_exp_pessoal</th>\n",
       "      <th>class_informacao</th>\n",
       "      <th>class_opiniao</th>\n",
       "      <th>class_parodia</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>date</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>place</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1502217</td>\n",
       "      <td>1000931012069724160</td>\n",
       "      <td>0.031485</td>\n",
       "      <td>0.504642</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>0.200243</td>\n",
       "      <td>0.152354</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>None</td>\n",
       "      <td>pt</td>\n",
       "      <td>na merda</td>\n",
       "      <td>None</td>\n",
       "      <td>Bwliebar_</td>\n",
       "      <td>minha irma brigando pq eu postei que Deus e zi...</td>\n",
       "      <td>2551219417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1502218</td>\n",
       "      <td>1000933497240981507</td>\n",
       "      <td>0.114587</td>\n",
       "      <td>0.104780</td>\n",
       "      <td>0.085701</td>\n",
       "      <td>0.220957</td>\n",
       "      <td>0.473975</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>@Crente_Quadrado preciso conversar com noe sob...</td>\n",
       "      <td>pt</td>\n",
       "      <td>Paraiso do Norte, Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>bielrobati</td>\n",
       "      <td>@Crente_Quadrado preciso conversar com noe sob...</td>\n",
       "      <td>180148246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1502219</td>\n",
       "      <td>1000934479580590080</td>\n",
       "      <td>0.064492</td>\n",
       "      <td>0.575904</td>\n",
       "      <td>0.160251</td>\n",
       "      <td>0.077597</td>\n",
       "      <td>0.121755</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>None</td>\n",
       "      <td>pt</td>\n",
       "      <td>Sao Leopoldo, Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>CarLouhs</td>\n",
       "      <td>Mano, que dor no meu pescoco acho que e dengue</td>\n",
       "      <td>949441490790551554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1502220</td>\n",
       "      <td>1000934567551922176</td>\n",
       "      <td>0.036469</td>\n",
       "      <td>0.071213</td>\n",
       "      <td>0.560594</td>\n",
       "      <td>0.117393</td>\n",
       "      <td>0.214331</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>None</td>\n",
       "      <td>pt</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>None</td>\n",
       "      <td>gds506</td>\n",
       "      <td>Zancudo Aedes aegypti genera resistencia a ins...</td>\n",
       "      <td>15686478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1502221</td>\n",
       "      <td>1000934642193780738</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.417638</td>\n",
       "      <td>0.247061</td>\n",
       "      <td>0.086871</td>\n",
       "      <td>0.235281</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>None</td>\n",
       "      <td>pt</td>\n",
       "      <td>Sao Paulo, Brasil</td>\n",
       "      <td>None</td>\n",
       "      <td>duda_senam</td>\n",
       "      <td>RT @fluminenseraiz: VAI TOMAR NO CU O FLUMINEN...</td>\n",
       "      <td>532225289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id  class_campanha  class_exp_pessoal  \\\n",
       "1502217  1000931012069724160        0.031485           0.504642   \n",
       "1502218  1000933497240981507        0.114587           0.104780   \n",
       "1502219  1000934479580590080        0.064492           0.575904   \n",
       "1502220  1000934567551922176        0.036469           0.071213   \n",
       "1502221  1000934642193780738        0.013150           0.417638   \n",
       "\n",
       "         class_informacao  class_opiniao  class_parodia coordinates  \\\n",
       "1502217          0.111274       0.200243       0.152354        None   \n",
       "1502218          0.085701       0.220957       0.473975        None   \n",
       "1502219          0.160251       0.077597       0.121755        None   \n",
       "1502220          0.560594       0.117393       0.214331        None   \n",
       "1502221          0.247061       0.086871       0.235281        None   \n",
       "\n",
       "              date                                     extended_tweet lang  \\\n",
       "1502217 2018-05-27                                               None   pt   \n",
       "1502218 2018-05-27  @Crente_Quadrado preciso conversar com noe sob...   pt   \n",
       "1502219 2018-05-27                                               None   pt   \n",
       "1502220 2018-05-27                                               None   pt   \n",
       "1502221 2018-05-27                                               None   pt   \n",
       "\n",
       "                         location place screen_name  \\\n",
       "1502217                  na merda  None   Bwliebar_   \n",
       "1502218  Paraiso do Norte, Brasil  None  bielrobati   \n",
       "1502219      Sao Leopoldo, Brasil  None    CarLouhs   \n",
       "1502220                Costa Rica  None      gds506   \n",
       "1502221         Sao Paulo, Brasil  None  duda_senam   \n",
       "\n",
       "                                                      text             user_id  \n",
       "1502217  minha irma brigando pq eu postei que Deus e zi...          2551219417  \n",
       "1502218  @Crente_Quadrado preciso conversar com noe sob...           180148246  \n",
       "1502219     Mano, que dor no meu pescoco acho que e dengue  949441490790551554  \n",
       "1502220  Zancudo Aedes aegypti genera resistencia a ins...            15686478  \n",
       "1502221  RT @fluminenseraiz: VAI TOMAR NO CU O FLUMINEN...           532225289  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = data.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file = os.path.join(outputs,'tweets_filtered.json')\n",
    "json.dump(json.loads(data_json), open(file, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(outputs,'tweets_filtered.json.bz2')\n",
    "data = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter by 7 weeks  timespan on each year\n",
    "Those weeks correspond to a peak for each virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['date'] >= '2016-02-14 00:00:01') & (data['date'] <= '2016-04-09 23:59:59') \\\n",
    "                 | (data['date'] >= '2017-03-05 00:00:01') & (data['date'] <= '2017-04-29 23:59:59') \\\n",
    "                 | (data['date'] >= '2018-04-01 00:00:01') & (data['date'] <= '2018-05-27 23:59:59') \\\n",
    "    ]\n",
    "data = data[data['lang'] == 'pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055095\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_section = data[(data['date'] >= '2016-02-14 00:00:01') & (data['date'] <= '2016-04-09 23:59:59')].sample(10000)\n",
    "data_section = data_section.append(data[(data['date'] >= '2017-03-05 00:00:01') & (data['date'] <= '2017-04-29 23:59:59')].sample(10000))\n",
    "data_section = data_section.append(data[(data['date'] >= '2018-04-01 00:00:01') & (data['date'] <= '2018-05-27 23:59:59')].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "data = data_section\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save a sample as input for training\n",
    "We need 5000 samples. First I get 6000 to remove possible duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(6000)\n",
    "sample.drop_duplicates(subset=['text'], keep='first', inplace=True)\n",
    "sample = sample.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_object = []\n",
    "count = 0\n",
    "for index, row in sample.iterrows():\n",
    "    sample_dict = {}\n",
    "    sample_dict['id'] = row['_id']\n",
    "    if isinstance(row['extended_tweet'], str):\n",
    "        text = re.sub('\\n+', ' ', row['extended_tweet'])\n",
    "        #print(text)\n",
    "    else:\n",
    "        text = re.sub('\\n+', ' ', row['text'])\n",
    "    sample_dict['message'] = text\n",
    "    sample_dict['count'] = count\n",
    "    tweets_object.append(sample_dict)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(outputs, 'tweets_anvil_input.json')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "json.dump(tweets_object, open(file, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "1723\n",
      "1507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "D:\\Users\\Marcelo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "print(len(sample[(sample['date'] >= '2016-02-14 00:00:01') & (sample['date'] <= '2016-04-09 23:59:59')]))\n",
    "print(len(sample[(sample['date'] >= '2017-03-05 00:00:01') & (data['date'] <= '2017-04-29 23:59:59')]))\n",
    "print(len(sample[(sample['date'] >= '2018-04-01 00:00:01') & (data['date'] <= '2018-05-27 23:59:59')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample[sample.duplicated(['text'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If nothing was printed, all tweets are identified as in portuguese language\n"
     ]
    }
   ],
   "source": [
    "for index, row in sample.iterrows(): \n",
    "    if row[9] != 'pt': print(row[9], '-----', row[1])\n",
    "print('If nothing was printed, all tweets are identified as in portuguese language')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check id that should have extended_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_len = 7503436\n",
    "obj = collection_ufmg.find_one({\"_id\": 718277523306594300})\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_object = json.load(open(file, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Charbrevolution https://t.co/vwZsyRqyAz https://t.co/RSU6IJsNTZ https://t.co/kklzwhHCWU https://t.co/Xzji1Oj3GY https://t.co/7B4q8bN3UC https://t.co/Bwq4Zxf4h5 https://t.co/zLs9DOMLVY  https://t.co/R0ZjWz5WxZ'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_object[0]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_texts = []\n",
    "long_texts = []\n",
    "count_long = 0\n",
    "count_short = 0\n",
    "for obj in tweets_object:\n",
    "    text = obj['message']\n",
    "    if len(text)>140: \n",
    "        count_long += 1\n",
    "        long_texts.append([obj['id'],text])\n",
    "    elif len(text)>=137 and len(text)<=140: \n",
    "        count_short += 1\n",
    "        cut_texts.append([obj['id'],text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(count_short)\n",
    "print(count_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
